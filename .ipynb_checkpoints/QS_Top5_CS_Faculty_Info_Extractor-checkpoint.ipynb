{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stupid-setting",
   "metadata": {},
   "source": [
    "The purpose of this script is to extract faculty information from the Top 5 QS-Ranked CS schools.\n",
    "\n",
    "Following that, the extracted faculty info will be used to map to dblp data, in order to query and retrieve associated publication info for our future analysis.\n",
    "\n",
    "From the following article: https://www.topuniversities.com/university-rankings-articles/university-subject-rankings/top-computer-science-schools-2021\n",
    "We note the top 5 universities as follow: \n",
    "1. MIT: \n",
    "- https://www.eecs.mit.edu/people/faculty-advisors/34 (CS, AI)\n",
    "- https://www.eecs.mit.edu/people/faculty-advisors/32 (CS, Systems)\n",
    "- https://www.eecs.mit.edu/people/faculty-advisors/35 (CS, Theory)\n",
    "- https://www.eecs.mit.edu/people/lecturer (Lecturer)\n",
    "2. Stanford: \n",
    "- https://cs.stanford.edu/directory/faculty\n",
    "3. CMU: \n",
    "- https://csd.cmu.edu/directory/faculty\n",
    "4. NUS: \n",
    "- https://www.comp.nus.edu.sg/about/depts/cs/faculty/\n",
    "5. UCB: \n",
    "- https://www2.eecs.berkeley.edu/Faculty/Lists/CS/faculty.html?_ga=2.57244906.1713537701.1616564430-341988066.1616564430 (CS Faculty)\n",
    "- https://www2.eecs.berkeley.edu/Faculty/Lists/teaching.html?_ga=2.57244906.1713537701.1616564430-341988066.1616564430 (Teaching Faculty)\n",
    "\n",
    "We shall start with the special snowflake, MIT first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-portrait",
   "metadata": {},
   "source": [
    "# NEW ADDITION\n",
    "Might need to account for Lecturers in:\n",
    "- (MIT; another link)\n",
    "- (Stanford; 2nd table instance, done)\n",
    "- (no need for CMU, all consolidated in one list!)\n",
    "- (NUS; bloody special snowflake with 4 separate tables)\n",
    "- UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "authentic-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pickle\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-province",
   "metadata": {},
   "source": [
    "# 1. MIT Faculty Name List Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "valued-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_mit_list():\n",
    "    \n",
    "    url_list = [ \n",
    "        'https://www.eecs.mit.edu/people/faculty-advisors/34',\n",
    "        'https://www.eecs.mit.edu/people/faculty-advisors/32',\n",
    "        'https://www.eecs.mit.edu/people/faculty-advisors/35',\n",
    "        'https://www.eecs.mit.edu/people/lecturer'\n",
    "    ]\n",
    "\n",
    "    # BS4 steps to get MIT CS, AI faculty soup and details\n",
    "    page = requests.get(url_list[0])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(\"ul\", {\"class\": \"faculty-list\"})\n",
    "    r_list = results.find_all('span', class_='field-content card-title')\n",
    "    # List to store CS, AI faculty names\n",
    "    mit_cs_ai_list = [each.getText() for each in r_list]\n",
    "\n",
    "    # BS4 steps to get MIT CS, Systems faculty soup and details\n",
    "    page = requests.get(url_list[1])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(\"ul\", {\"class\": \"faculty-list\"})\n",
    "    r_list = results.find_all('span', class_='field-content card-title')\n",
    "    # List to store CS, Systems faculty names\n",
    "    mit_cs_systems_list = [each.getText() for each in r_list]\n",
    "\n",
    "    # BS4 steps to get MIT CS, Theory faculty soup and details\n",
    "    page = requests.get(url_list[2])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(\"ul\", {\"class\": \"faculty-list\"})\n",
    "    r_list = results.find_all('span', class_='field-content card-title')\n",
    "    # List to store CS, Theory faculty names\n",
    "    mit_cs_theory_list = [each.getText() for each in r_list]\n",
    "    \n",
    "    # BS4 steps to get MIT lecturer faculty soup and details    \n",
    "    page = requests.get('https://www.eecs.mit.edu/people/lecturer')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(\"ul\", {\"class\": \"faculty-list\"})\n",
    "    r_list = results.find_all('span', class_='field-content card-title')\n",
    "    # List to store lecturer faculty names\n",
    "    mit_cs_lecturer_list = [each.getText() for each in r_list]    \n",
    "    \n",
    "    return mit_cs_ai_list, mit_cs_systems_list, mit_cs_theory_list, mit_cs_lecturer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-classification",
   "metadata": {},
   "source": [
    "# 2. Stanford Faculty Name List Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "laughing-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to include lecturers\n",
    "def retrieve_stanford_list():\n",
    "\n",
    "    '''\n",
    "    results[0] - Regular Faculty Members\n",
    "    results[1] - Lecturer Faculty Members\n",
    "    '''        \n",
    "    \n",
    "    # BS4 steps to get Stanford CS faculty soup and details\n",
    "    page = requests.get('https://cs.stanford.edu/directory/faculty')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all(\"table\")\n",
    "    \n",
    "    # List to store Stanford CS Regular faculty names\n",
    "    stanford_regular_list = []\n",
    "    for row in results[0].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        stanford_regular_list.append(fac_name)\n",
    "        \n",
    "    # List to store Stanford CS Lecturer faculty names\n",
    "    stanford_lecturer_list = []\n",
    "    for row in results[0].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        stanford_lecturer_list.append(fac_name)\n",
    "    \n",
    "    return stanford_regular_list, stanford_lecturer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-geometry",
   "metadata": {},
   "source": [
    "# 3. CMU Faculty Name List Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mineral-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_cmu_list():\n",
    "\n",
    "    # BS4 steps to get CMU CS faculty soup and details\n",
    "    page = requests.get('https://csd.cmu.edu/directory/faculty')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(\"tbody\")\n",
    "    # List to store CMU CS faculty names\n",
    "    cmu_cs_list = []\n",
    "    for row in results.find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        cmu_cs_list.append(fac_name)\n",
    "\n",
    "    return cmu_cs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-agenda",
   "metadata": {},
   "source": [
    "# 4. NUS Faculty Name List Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affected-germany",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'find_all'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-599cc3529f27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# List to store CMU CS faculty names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcmu_cs_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"td\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mfac_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2172\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2173\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m   2174\u001b[0m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2175\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'find_all'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "# BS4 steps to get NUS CS faculty soup and details\n",
    "page = requests.get('https://www.comp.nus.edu.sg/about/depts/cs/faculty/')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "results = soup.find_all(\"tbody\")\n",
    "# List to store CMU CS faculty names\n",
    "cmu_cs_list = []\n",
    "for row in results.find_all(\"tr\")[1:]:\n",
    "    col = row.find_all(\"td\")\n",
    "    fac_name = col[0].getText().strip()\n",
    "    cmu_cs_list.append(fac_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wrong-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_nus_list():\n",
    "    \n",
    "    '''\n",
    "    results[1] - Regular Faculty Members\n",
    "    results[2] - Joint Faculty Members\n",
    "    results[3] - Teaching Faculty Members\n",
    "    results[4] - Research Faculty Members\n",
    "\n",
    "    '''    \n",
    "    \n",
    "    # BS4 steps to get NUS CS faculty soup and details\n",
    "    page = requests.get('https://www.comp.nus.edu.sg/about/depts/cs/faculty/')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all(\"tbody\")\n",
    "    \n",
    "    # List to store NUS CS Regular faculty names\n",
    "    nus_regular_list = []\n",
    "    for row in results[1].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        nus_regular_list.append(fac_name)\n",
    "        \n",
    "    # List to store NUS CS Joint faculty names\n",
    "    nus_joint_list = []\n",
    "    for row in results[2].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        nus_joint_list.append(fac_name)\n",
    "        \n",
    "    # List to store NUS CS Teaching faculty names\n",
    "    nus_teaching_list = []\n",
    "    for row in results[3].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        nus_teaching_list.append(fac_name)\n",
    "        \n",
    "    # List to store NUS CS Research faculty names\n",
    "    nus_research_list = []\n",
    "    for row in results[3].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        nus_research_list.append(fac_name)\n",
    "    \n",
    "    return nus_regular_list, nus_joint_list, nus_teaching_list, nus_research_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-norwegian",
   "metadata": {},
   "source": [
    "# 5. UCB Faculty Name List Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "approved-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_ucb_list():\n",
    "\n",
    "    # BS4 steps to get UCB CS faculty soup and details\n",
    "    page = requests.get('https://www2.eecs.berkeley.edu/Faculty/Lists/CS/faculty.html?_ga=2.57244906.1713537701.1616564430-341988066.1616564430')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all(\"h3\", {\"class\": \"media-heading\"})\n",
    "\n",
    "    # List to store UCB CS faculty names\n",
    "    ucb_faculty_list = []\n",
    "    for each in results:\n",
    "        detail = each.find('a')\n",
    "        fac_name = detail.getText()\n",
    "        ucb_faculty_list.append(fac_name)\n",
    "\n",
    "    # BS4 steps to get UCB CS teaching soup and details\n",
    "    page = requests.get('https://www2.eecs.berkeley.edu/Faculty/Lists/teaching.html?_ga=2.57244906.1713537701.1616564430-341988066.1616564430')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all(\"h3\", {\"class\": \"media-heading\"})    \n",
    "\n",
    "    # List to store UCB CS teaching names\n",
    "    ucb_teaching_list = []\n",
    "    for each in results:\n",
    "        detail = each.find('a')\n",
    "        fac_name = detail.getText()\n",
    "        ucb_teaching_list.append(fac_name)\n",
    "\n",
    "    return ucb_faculty_list, ucb_teaching_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "asian-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "mit_cs_ai_list, mit_cs_systems_list, mit_cs_theory_list, mit_cs_lecturer_list = retrieve_mit_list()\n",
    "stanford_regular_list, stanford_lecturer_list = retrieve_stanford_list()\n",
    "cmu_cs_list = retrieve_cmu_list()\n",
    "nus_regular_list, nus_joint_list, nus_teaching_list, nus_research_list = retrieve_nus_list()\n",
    "ucb_faculty_list, ucb_teaching_list = retrieve_ucb_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faced-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_list = [[retrieve_mit_list()], [retrieve_stanford_list()], [retrieve_cmu_list()], [retrieve_nus_list()], [retrieve_ucb_list()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prospective-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_5_list.pkl', 'wb') as f:\n",
    "    pickle.dump(top_5_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "relative-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve pretty_soup_list with pickle\n",
    "with open('top_5_list.pkl', 'rb') as f:\n",
    "    top_5_list = pickle.load(f)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
