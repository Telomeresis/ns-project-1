{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appointed-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ordinary-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "asian-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import faculty details into df\n",
    "faculty_df = pd.read_excel('Faculty.xlsx')\n",
    "\n",
    "# Select relevant columns\n",
    "faculty_df = faculty_df[['Faculty', 'Position', 'Gender', 'Management', 'DBLP', 'Area']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-retailer",
   "metadata": {},
   "source": [
    "# Don't need to run this code for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reverse-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list for storing modified DBLP link to access XML variant w/ their API\n",
    "xml_list = []\n",
    "\n",
    "# Iterate over faculty_df and replace .html w/ .xml - updated to append .xml for missing .html cases\n",
    "for each in faculty_df['DBLP']:\n",
    "    if '.html' in each:\n",
    "        replaced_each = each.replace(\".html\", \".xml\")\n",
    "    xml_list.append(replaced_each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loose-korea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# Declare list to store extracted content\n",
    "content_list = []\n",
    "\n",
    "i = 0\n",
    "# Iterate using q_list to make a GET request to fetch raw HTML content\n",
    "for each in xml_list:\n",
    "    html_content = requests.get(each).text\n",
    "    content_list.append(html_content)\n",
    "    i+=1\n",
    "    if (i % 10 == 0):\n",
    "        print(i)\n",
    "    \n",
    "# Store content_list with pickle\n",
    "with open('content_list.pkl', 'wb') as f:\n",
    "    pickle.dump(content_list, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stone-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve content_list with pickle\n",
    "with open('content_list.pkl', 'rb') as f:\n",
    "    content_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signed-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare empty list for storing soups\n",
    "pretty_soup_list = []\n",
    "\n",
    "for each in content_list:\n",
    "    soup = BeautifulSoup(each, \"lxml\")\n",
    "    pretty_soup_list.append(soup.prettify())\n",
    "\n",
    "# Store pretty_soup_list with pickle\n",
    "with open('pretty_soup_list.pkl', 'wb') as f:\n",
    "    pickle.dump(pretty_soup_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-inquiry",
   "metadata": {},
   "source": [
    "# Run from here onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confused-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve pretty_soup_list with pickle\n",
    "with open('pretty_soup_list.pkl', 'rb') as f:\n",
    "    pretty_soup_list = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "floppy-germany",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Declare empty all_article_list\n",
    "all_article_list = []\n",
    "faculty_dblp_name_list = []\n",
    "\n",
    "# Iterate over pretty_soup_list + extract names because given names in excel aren't same as DBLP lmao\n",
    "for each in pretty_soup_list:\n",
    "    converted_each = BeautifulSoup(each, \"lxml\") # need to convert lmao\n",
    "    individual_article_list = converted_each.find_all('article')\n",
    "    #individual_article_list += converted_each.find_all('inproceedings')\n",
    "    all_article_list.append(individual_article_list)\n",
    "    try:\n",
    "        faculty_dblp_name = converted_each.dblpperson['name']\n",
    "    except:\n",
    "        faculty_dblp_name = converted_each.title.text.strip().strip('dblp: ') # omg cancerous code sorry\n",
    "    finally:\n",
    "        faculty_dblp_name_list.append(faculty_dblp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "seeing-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "all_article_list[0] <- Faculty, List Containing Articles\n",
    "all_article_list[0][0] <- Faculty, Individual Articles\n",
    "'''\n",
    "\n",
    "# Index for doing dict mapping later\n",
    "faculty_index = 0\n",
    "\n",
    "# declare empty lists for DF\n",
    "article_key_list = []\n",
    "article_mdate_list = []\n",
    "faculty_index_list = []\n",
    "title_list = []\n",
    "#pages_list = []\n",
    "year_list = []\n",
    "#volume_list = []\n",
    "#journal_list = []\n",
    "authors_list = []\n",
    "\n",
    "for each in all_article_list:\n",
    "    for article in each:\n",
    "        # Article Tag Extraction w/ Array Indexing\n",
    "        article_key = article[\"key\"]\n",
    "        article_mdate = article[\"mdate\"]\n",
    "        # Strip processing \n",
    "        stripped_title = article.title.text.strip()\n",
    "        #stripped_pages = article.pages.text.strip() <- apparently we have null pages somewhere?\n",
    "        stripped_year = article.year.text.strip()\n",
    "        #stripped_volume = article.volume.text.strip()\n",
    "        #stripped_journal = article.journal.text.strip() \n",
    "        stripped_authors = [each.text.strip() for each in article.find_all('author')] # list comprehension; bad space and time complexity  \n",
    "        # List appendage\n",
    "        article_key_list.append(article_key)\n",
    "        article_mdate_list.append(article_mdate)\n",
    "        faculty_index_list.append(faculty_index)\n",
    "        title_list.append(stripped_title)\n",
    "        #pages_list.append(stripped_pages)\n",
    "        year_list.append(stripped_year)\n",
    "        #volume_list.append(stripped_volume)\n",
    "        #journal_list.append(stripped_journal)\n",
    "        authors_list.append(stripped_authors)\n",
    "    faculty_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "protecting-shield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Code for inserting contribution into DF\\ncontribution_index_list = []\\nfor i, row in dblp_df.iterrows():\\n    if (row['DBLP Name'] in row['Full Authors List']): # check if DBLP name exists in Full Authors List\\n        ci = row['Full Authors List'].index(row['DBLP Name'])+1 # if so, retrieve index, +1 (to acccount for 0), then append to contribution_index_list\\n    elif (row['Faculty'] in row['Full Authors List']): # check if Faculty name exists in Full Authors List\\n        ci = row['Full Authors List'].index(row['Faculty'])+1\\n    else:\\n        ci = '-'\\n    contribution_index_list.append(ci)\\ndblp_df['Author Contribution Index'] = contribution_index_list # assigns a value based on how much contribution the author has made for a publication. 1 = Highest (Main)\\n\\n# Use DBLP Name Column to prune duplicate author info from 'Other Authors'colmumn row-by-row (because DBLP name is not same as Faculty name lmao)\\nfor i, row in dblp_df.iterrows():\\n    if (row['DBLP Name'] in row['Other Authors']): # check if DBLP faculty name exists in Other Authors.\\n        row['Other Authors'].remove(row['DBLP Name']) # if so, remove from Other Authors\\n    elif (row['Faculty'] in row['Other Authors']): # then check if faculty name exists in Other Authors\\n        row['Other Authors'].remove(row['Faculty']) # if so, remove from Other Authors\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare DF for DBLP\n",
    "dblp_df = pd.DataFrame()\n",
    "\n",
    "# Create dict mapping for Faculty, len is used as f_index.\n",
    "faculty_dict_mapping = dict(zip(range(len(faculty_df['Faculty'])), faculty_df['Faculty'],))\n",
    "\n",
    "# Create another dict mapping for actual DBLP names used for faculty members, len is used f_index\n",
    "faculty_dblp_name_dict_mapping = dict(zip(range(len(faculty_df['Faculty'])), faculty_dblp_name_list,))\n",
    "\n",
    "# Fill up dblp_DF\n",
    "dblp_df['f_index'] = faculty_index_list\n",
    "dblp_df['Faculty'] = dblp_df['f_index'].map(faculty_dict_mapping)\n",
    "#dblp_df['DBLP Name'] = dblp_df['f_index'].map(faculty_dblp_name_dict_mapping)\n",
    "dblp_df['key'] = article_key_list\n",
    "dblp_df['mdate'] = article_mdate_list\n",
    "dblp_df['Title'] = title_list\n",
    "dblp_df['Year'] = year_list\n",
    "#dblp_df['Volume'] = volume_list\n",
    "#dblp_df['Journal'] = journal_list\n",
    "#dblp_df['Other Authors'] = authors_list\n",
    "dblp_df['Full Authors List'] = authors_list\n",
    "\n",
    "'''\n",
    "# Code for inserting contribution into DF\n",
    "contribution_index_list = []\n",
    "for i, row in dblp_df.iterrows():\n",
    "    if (row['DBLP Name'] in row['Full Authors List']): # check if DBLP name exists in Full Authors List\n",
    "        ci = row['Full Authors List'].index(row['DBLP Name'])+1 # if so, retrieve index, +1 (to acccount for 0), then append to contribution_index_list\n",
    "    elif (row['Faculty'] in row['Full Authors List']): # check if Faculty name exists in Full Authors List\n",
    "        ci = row['Full Authors List'].index(row['Faculty'])+1\n",
    "    else:\n",
    "        ci = '-'\n",
    "    contribution_index_list.append(ci)\n",
    "dblp_df['Author Contribution Index'] = contribution_index_list # assigns a value based on how much contribution the author has made for a publication. 1 = Highest (Main)\n",
    "\n",
    "# Use DBLP Name Column to prune duplicate author info from 'Other Authors'colmumn row-by-row (because DBLP name is not same as Faculty name lmao)\n",
    "for i, row in dblp_df.iterrows():\n",
    "    if (row['DBLP Name'] in row['Other Authors']): # check if DBLP faculty name exists in Other Authors.\n",
    "        row['Other Authors'].remove(row['DBLP Name']) # if so, remove from Other Authors\n",
    "    elif (row['Faculty'] in row['Other Authors']): # then check if faculty name exists in Other Authors\n",
    "        row['Other Authors'].remove(row['Faculty']) # if so, remove from Other Authors\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "enormous-howard",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Author Contribution Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Author Contribution Index'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5ffd5256cf12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdblp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdblp_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Author Contribution Index'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Author Contribution Index'"
     ]
    }
   ],
   "source": [
    "dblp_df.loc[dblp_df['Author Contribution Index'] == '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "chief-roots",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_index</th>\n",
       "      <th>Faculty</th>\n",
       "      <th>key</th>\n",
       "      <th>mdate</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Full Authors List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A S Madhukumar</td>\n",
       "      <td>journals/cssp/MathewSVM20</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>An Adaptive Energy Detection Scheme with Real-...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Libin K. Mathew, Shanker Shreejith, A. Prasad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A S Madhukumar</td>\n",
       "      <td>journals/ijscn/SiriginaMB20</td>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>Analysis of heterogeneous satellite networks w...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Rajendra Prasad Sirigina, Mark D. J. Bowyer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A S Madhukumar</td>\n",
       "      <td>journals/ijscn/SiriginaMB20a</td>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>Terrestrial Relay-Aided Cooperative High Throu...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Rajendra Prasad Sirigina, Mark D. J. Bowyer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A S Madhukumar</td>\n",
       "      <td>journals/taes/RamabadranMW20</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>Blind Estimation of Code Parameters for Produc...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Swaminathan Ramabadran, Guohua Wang]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A S Madhukumar</td>\n",
       "      <td>journals/tgcn/RaoMS20</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>Wireless Energy Harvesting-Based Relaying: A F...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Yepuri Sudhakara Rao, Rajendra Prasad Sirigina]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_index         Faculty                           key       mdate  \\\n",
       "0        0  A S Madhukumar     journals/cssp/MathewSVM20  2020-10-20   \n",
       "1        0  A S Madhukumar   journals/ijscn/SiriginaMB20  2020-08-12   \n",
       "2        0  A S Madhukumar  journals/ijscn/SiriginaMB20a  2020-08-12   \n",
       "3        0  A S Madhukumar  journals/taes/RamabadranMW20  2020-05-04   \n",
       "4        0  A S Madhukumar         journals/tgcn/RaoMS20  2020-06-18   \n",
       "\n",
       "                                               Title  Year  \\\n",
       "0  An Adaptive Energy Detection Scheme with Real-...  2020   \n",
       "1  Analysis of heterogeneous satellite networks w...  2020   \n",
       "2  Terrestrial Relay-Aided Cooperative High Throu...  2020   \n",
       "3  Blind Estimation of Code Parameters for Produc...  2020   \n",
       "4  Wireless Energy Harvesting-Based Relaying: A F...  2020   \n",
       "\n",
       "                                   Full Authors List  \n",
       "0  [Libin K. Mathew, Shanker Shreejith, A. Prasad...  \n",
       "1      [Rajendra Prasad Sirigina, Mark D. J. Bowyer]  \n",
       "2      [Rajendra Prasad Sirigina, Mark D. J. Bowyer]  \n",
       "3              [Swaminathan Ramabadran, Guohua Wang]  \n",
       "4   [Yepuri Sudhakara Rao, Rajendra Prasad Sirigina]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dblp_df.head(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-evolution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testarossa_df = dblp_df.loc[dblp_df['Author Contribution Index'] == '-']\n",
    "testarossa_df['DBLP Name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-privacy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dblp_df.to_csv(r'dblp_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "regional-content",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'S', 'Madhukumar']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Shanker Shreejith'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_name_form_in_list(fac_name, authors_list):\n",
    "    mod_fac_name = fac_name.replace(\"-\", \" \")\n",
    "    mod_fac_name_list = mod_fac_name.split(\" \")\n",
    "    print(mod_fac_name_list)\n",
    "    best_i = 0\n",
    "    best_count = 0\n",
    "    \n",
    "    for i in range(len(authors_list)):\n",
    "        #check matchability\n",
    "        author = authors_list[i]\n",
    "        count = 0\n",
    "        for w in mod_fac_name_list:\n",
    "            if w in author:\n",
    "                count += 1\n",
    "        if count > best_count:\n",
    "            best_count = count \n",
    "            best_i = i\n",
    "    return authors_list[best_i]\n",
    "\n",
    "find_name_form_in_list(dblp_df.iloc[0, 1], dblp_df.iloc[0,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-spending",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
