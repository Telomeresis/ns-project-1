{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appointed-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ordinary-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "asian-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import faculty details into df\n",
    "faculty_df = pd.read_excel('Faculty.xlsx')\n",
    "\n",
    "# Select relevant columns\n",
    "faculty_df = faculty_df[['Faculty', 'Position', 'Gender', 'Management', 'DBLP', 'Area']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-retailer",
   "metadata": {},
   "source": [
    "# Don't need to run this code for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reverse-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list for storing modified DBLP link to access XML variant w/ their API\n",
    "xml_list = []\n",
    "\n",
    "# Iterate over faculty_df and replace .html w/ .xml - updated to append .xml for missing .html cases\n",
    "for each in faculty_df['DBLP']:\n",
    "    if '.html' in each:\n",
    "        replaced_each = each.replace(\".html\", \".xml\")\n",
    "    xml_list.append(replaced_each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "loose-korea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b37832154f48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Iterate using q_list to make a GET request to fetch raw HTML content\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxml_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mhtml_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meach\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mcontent_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1008\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mtls_in_tls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    170\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             )\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nsenv\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Declare list to store extracted content\n",
    "content_list = []\n",
    "\n",
    "i = 0\n",
    "# Iterate using q_list to make a GET request to fetch raw HTML content\n",
    "for each in xml_list:\n",
    "    html_content = requests.get(each).text\n",
    "    content_list.append(html_content)\n",
    "    i+=1\n",
    "    if (i % 10 == 0):\n",
    "        print(i)\n",
    "    \n",
    "# Store content_list with pickle\n",
    "with open('content_list.pkl', 'wb') as f:\n",
    "    pickle.dump(content_list, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve content_list with pickle\n",
    "with open('content_list.pkl', 'rb') as f:\n",
    "    content_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare empty list for storing soups\n",
    "pretty_soup_list = []\n",
    "\n",
    "for each in content_list:\n",
    "    soup = BeautifulSoup(each, \"lxml\")\n",
    "    pretty_soup_list.append(soup.prettify())\n",
    "\n",
    "# Store pretty_soup_list with pickle\n",
    "with open('pretty_soup_list.pkl', 'wb') as f:\n",
    "    pickle.dump(pretty_soup_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve pretty_soup_list with pickle\n",
    "with open('pretty_soup_list.pkl', 'rb') as f:\n",
    "    pretty_soup_list = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-germany",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Declare empty all_article_list\n",
    "all_article_list = []\n",
    "faculty_dblp_name_list = []\n",
    "\n",
    "# Iterate over pretty_soup_list + extract names because given names in excel aren't same as DBLP lmao\n",
    "for each in pretty_soup_list:\n",
    "    converted_each = BeautifulSoup(each, \"lxml\") # need to convert lmao\n",
    "    individual_article_list = converted_each.find_all('article')\n",
    "    individual_article_list += converted_each.find_all('inproceedings')\n",
    "    all_article_list.append(individual_article_list)\n",
    "    try:\n",
    "        faculty_dblp_name = converted_each.dblpperson['name']\n",
    "    except:\n",
    "        faculty_dblp_name = converted_each.title.text.strip().strip('dblp: ') # omg cancerous code sorry\n",
    "    finally:\n",
    "        #print(faculty_dblp_name)\n",
    "        faculty_dblp_name_list.append(faculty_dblp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare DF for DBLP\n",
    "COLUMN_NAMES=[\n",
    "    'f_index',\n",
    "    'Faculty',\n",
    "    'key',\n",
    "    'Year',\n",
    "    'Full Authors List'\n",
    "]\n",
    "dblp_df = pd.DataFrame(columns=COLUMN_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "all_article_list[0] <- Faculty, List Containing Articles\n",
    "all_article_list[0][0] <- Faculty, Individual Articles\n",
    "'''\n",
    "\n",
    "# Index for doing dict mapping later\n",
    "faculty_index = 0\n",
    "\n",
    "# declare empty lists for DF\n",
    "article_key_list = []\n",
    "article_mdate_list = []\n",
    "faculty_index_list = []\n",
    "title_list = []\n",
    "year_list = []\n",
    "authors_list = []\n",
    "\n",
    "for each in all_article_list:\n",
    "    for article in each:\n",
    "        # Article Tag Extraction w/ Array Indexing\n",
    "        article_key = article[\"key\"]\n",
    "        article_mdate = article[\"mdate\"]\n",
    "        # Strip processing \n",
    "        stripped_year = article.year.text.strip()\n",
    "        stripped_authors = [each.text.strip() for each in article.find_all('author')] # list comprehension; bad space and time complexity  \n",
    "        # Append to df\n",
    "        append_dict = {'f_index': faculty_index, 'Faculty': '', 'key': article_key, 'Year': stripped_year, 'Full Authors List': stripped_authors}\n",
    "        dblp_df = dblp_df.append(append_dict, ignore_index=True)\n",
    "        \n",
    "    faculty_index+=1\n",
    "    \n",
    "# Create dict mapping for Faculty, len is used as f_index.\n",
    "faculty_dict_mapping = dict(zip(range(len(faculty_df['Faculty'])), faculty_df['Faculty'],))\n",
    "dblp_df['Faculty'] = dblp_df['f_index'].map(faculty_dict_mapping)\n",
    "\n",
    "# Store dblp_df with pickle\n",
    "with open('dblp_12k_df.pkl', 'wb') as f:\n",
    "    pickle.dump(dblp_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-loading",
   "metadata": {},
   "source": [
    "# Run from here onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "french-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve dblp_df with pickle\n",
    "with open('dblp_12k_df.pkl', 'rb') as f:\n",
    "    dblp_df = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "regional-content",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A. S. Madhukumar'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_name_form_in_list(fac_name, authors_list):\n",
    "    mod_fac_name = fac_name.replace(\"-\", \" \")\n",
    "    mod_fac_name_list = mod_fac_name.split(\" \")\n",
    "    #print(mod_fac_name_list)\n",
    "    best_i = 0\n",
    "    best_count = 0\n",
    "    \n",
    "    for i in range(len(authors_list)):\n",
    "        #check matchability\n",
    "        author = authors_list[i]\n",
    "        count = 0\n",
    "        for w in mod_fac_name_list:\n",
    "            if w in author:\n",
    "                count += 1\n",
    "        if count > best_count:\n",
    "            best_count = count \n",
    "            best_i = i\n",
    "    return authors_list[best_i]\n",
    "\n",
    "find_name_form_in_list(dblp_df.iloc[0, 1], dblp_df.iloc[0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "declared-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_df[\"published_name\"] = dblp_df.apply(lambda row: find_name_form_in_list(row[\"Faculty\"], row[\"Full Authors List\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "earned-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for inserting contribution into DF\n",
    "contribution_index_list = []\n",
    "for i, row in dblp_df.iterrows():\n",
    "    if (row['published_name'] in row['Full Authors List']): # check if DBLP name exists in Full Authors List\n",
    "        ci = row['Full Authors List'].index(row['published_name'])+1 # if so, retrieve index, +1 (to acccount for 0), then append to contribution_index_list\n",
    "    else:\n",
    "        ci = '-'\n",
    "    contribution_index_list.append(ci)\n",
    "dblp_df['Author Contribution Index'] = contribution_index_list # assigns a value based on how much contribution the author has made for a publication. 1 = Highest (Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DBLP Name Column to prune duplicate author info from 'Other Authors'colmumn row-by-row (because DBLP name is not same as Faculty name lmao)\n",
    "authors_list = dblp_df['Full Authors List'].tolist()\n",
    "#dblp_df['Other Authors'] = authors_list.copy()\n",
    "#dblp_df['Other Authors'] = others_list # assigns a value based on how much contribution the author has made for a publication. 1 = Highest (Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "industrial-laser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def prune_name_from_other_authors_list(fac_name, authors_list):\n",
    "    mod_fac_name = fac_name.replace(\"-\", \" \")\n",
    "    mod_fac_name_list = mod_fac_name.split(\" \")\n",
    "    #print(mod_fac_name_list)\n",
    "    best_i = 0\n",
    "    best_count = 0\n",
    "    \n",
    "    for i in range(len(authors_list)):\n",
    "        #check matchability\n",
    "        author = authors_list[i]\n",
    "        count = 0\n",
    "        for w in mod_fac_name_list:\n",
    "            if w in author:\n",
    "                count += 1\n",
    "        if count > best_count:\n",
    "            best_count = count \n",
    "            best_i = i\n",
    "    authors_list.remove(authors_list[best_i])\n",
    "    return authors_list\n",
    "\n",
    "# Use DBLP Name Column to prune duplicate author info from 'Other Authors'colmumn row-by-row (because DBLP name is not same as Faculty name lmao)\n",
    "dblp_df['Other Authors'] = dblp_df['Full Authors List'].copy() # assigns a value based on how much contribution the author has made for a publication. 1 = Highest (Main)\n",
    "dblp_df.apply(lambda row: prune_name_from_other_authors_list(row[\"Faculty\"], row[\"Other Authors\"]), axis = 1)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "respiratory-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_df.to_csv(r'dblp_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "controlling-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_index</th>\n",
       "      <th>Faculty</th>\n",
       "      <th>key</th>\n",
       "      <th>Year</th>\n",
       "      <th>published_name</th>\n",
       "      <th>Other Authors</th>\n",
       "      <th>Author Contribution Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [f_index, Faculty, key, Year, published_name, Other Authors, Author Contribution Index]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dblp_df[dblp_df['Author Contribution Index'] == '-' ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
