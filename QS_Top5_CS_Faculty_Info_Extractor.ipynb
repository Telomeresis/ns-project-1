{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stupid-setting",
   "metadata": {},
   "source": [
    "The purpose of this script is to extract faculty information from the Top 5 QS-Ranked CS schools.\n",
    "\n",
    "Following that, the extracted faculty info will be used to map to dblp data, in order to query and retrieve associated publication info for our future analysis.\n",
    "\n",
    "From the following article: https://www.topuniversities.com/university-rankings-articles/university-subject-rankings/top-computer-science-schools-2021\n",
    "We note the top 5 universities as follow: \n",
    "1. MIT: \n",
    "- https://www.eecs.mit.edu/people/faculty-advisors/34 (CS, AI)\n",
    "- https://www.eecs.mit.edu/people/faculty-advisors/32 (CS, Systems)\n",
    "- https://www.eecs.mit.edu/people/faculty-advisors/35 (CS, Theory)\n",
    "- https://www.eecs.mit.edu/people/lecturer (Lecturer)\n",
    "2. Stanford: \n",
    "- https://cs.stanford.edu/directory/faculty\n",
    "3. CMU: \n",
    "- https://csd.cmu.edu/directory/faculty\n",
    "4. NUS: \n",
    "- https://www.comp.nus.edu.sg/about/depts/cs/faculty/\n",
    "5. UCB: \n",
    "- https://www2.eecs.berkeley.edu/Faculty/Lists/CS/faculty.html?_ga=2.57244906.1713537701.1616564430-341988066.1616564430 (CS Faculty)\n",
    "- https://www2.eecs.berkeley.edu/Faculty/Lists/teaching.html?_ga=2.57244906.1713537701.1616564430-341988066.1616564430 (Teaching Faculty)\n",
    "\n",
    "We shall start with the special snowflake, MIT first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-portrait",
   "metadata": {},
   "source": [
    "# NEW ADDITION\n",
    "Might need to account for Lecturers in:\n",
    "- (MIT; another link)\n",
    "- (Stanford; 2nd table instance, done)\n",
    "- (no need for CMU, all consolidated in one list!)\n",
    "- (NUS; bloody special snowflake with 4 separate tables)\n",
    "- UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authentic-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pickle\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-province",
   "metadata": {},
   "source": [
    "# 1. MIT Faculty Name List Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valued-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_mit_list():\n",
    "    \n",
    "    url_list = [ \n",
    "        'https://www.eecs.mit.edu/people/faculty-advisors/34',\n",
    "        'https://www.eecs.mit.edu/people/faculty-advisors/32',\n",
    "        'https://www.eecs.mit.edu/people/faculty-advisors/35',\n",
    "        'https://www.eecs.mit.edu/people/lecturer'\n",
    "    ]\n",
    "\n",
    "    # BS4 steps to get MIT CS, AI faculty soup and details\n",
    "    page = requests.get(url_list[0])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(\"ul\", {\"class\": \"faculty-list\"})\n",
    "    r_list = results.find_all('span', class_='field-content card-title')\n",
    "    # List to store CS, AI faculty names\n",
    "    mit_cs_ai_list = [each.getText() for each in r_list]\n",
    "\n",
    "    # BS4 steps to get MIT CS, Systems faculty soup and details\n",
    "    page = requests.get(url_list[1])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(\"ul\", {\"class\": \"faculty-list\"})\n",
    "    r_list = results.find_all('span', class_='field-content card-title')\n",
    "    # List to store CS, Systems faculty names\n",
    "    mit_cs_systems_list = [each.getText() for each in r_list]\n",
    "\n",
    "    # BS4 steps to get MIT CS, Theory faculty soup and details\n",
    "    page = requests.get(url_list[2])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(\"ul\", {\"class\": \"faculty-list\"})\n",
    "    r_list = results.find_all('span', class_='field-content card-title')\n",
    "    # List to store CS, Theory faculty names\n",
    "    mit_cs_theory_list = [each.getText() for each in r_list]\n",
    "    \n",
    "    # BS4 steps to get MIT lecturer faculty soup and details    \n",
    "    page = requests.get('https://www.eecs.mit.edu/people/lecturer')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(\"ul\", {\"class\": \"faculty-list\"})\n",
    "    r_list = results.find_all('span', class_='field-content card-title')\n",
    "    # List to store lecturer faculty names\n",
    "    mit_cs_lecturer_list = [each.getText() for each in r_list]    \n",
    "    \n",
    "    return mit_cs_ai_list, mit_cs_systems_list, mit_cs_theory_list, mit_cs_lecturer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-classification",
   "metadata": {},
   "source": [
    "# 2. Stanford Faculty Name List Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "laughing-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to include lecturers\n",
    "def retrieve_stanford_list():\n",
    "\n",
    "    '''\n",
    "    results[0] - Regular Faculty Members\n",
    "    results[1] - Lecturer Faculty Members\n",
    "    '''        \n",
    "    \n",
    "    # BS4 steps to get Stanford CS faculty soup and details\n",
    "    page = requests.get('https://cs.stanford.edu/directory/faculty')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all(\"table\")\n",
    "    \n",
    "    # List to store Stanford CS Regular faculty names\n",
    "    stanford_regular_list = []\n",
    "    for row in results[0].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        stanford_regular_list.append(fac_name)\n",
    "        \n",
    "    # List to store Stanford CS Lecturer faculty names\n",
    "    stanford_lecturer_list = []\n",
    "    for row in results[0].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        stanford_lecturer_list.append(fac_name)\n",
    "    \n",
    "    return stanford_regular_list, stanford_lecturer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-geometry",
   "metadata": {},
   "source": [
    "# 3. CMU Faculty Name List Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mineral-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_cmu_list():\n",
    "\n",
    "    # BS4 steps to get CMU CS faculty soup and details\n",
    "    page = requests.get('https://csd.cmu.edu/directory/faculty')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(\"tbody\")\n",
    "    # List to store CMU CS faculty names\n",
    "    cmu_cs_list = []\n",
    "    for row in results.find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        cmu_cs_list.append(fac_name)\n",
    "\n",
    "    return cmu_cs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-agenda",
   "metadata": {},
   "source": [
    "# 4. NUS Faculty Name List Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wrong-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_nus_list():\n",
    "    \n",
    "    '''\n",
    "    results[1] - Regular Faculty Members\n",
    "    results[2] - Joint Faculty Members\n",
    "    results[3] - Teaching Faculty Members\n",
    "    results[4] - Research Faculty Members\n",
    "\n",
    "    '''    \n",
    "    \n",
    "    # BS4 steps to get NUS CS faculty soup and details\n",
    "    page = requests.get('https://www.comp.nus.edu.sg/about/depts/cs/faculty/')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all(\"tbody\")\n",
    "    \n",
    "    # List to store NUS CS Regular faculty names\n",
    "    nus_regular_list = []\n",
    "    for row in results[1].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        nus_regular_list.append(fac_name)\n",
    "        \n",
    "    # List to store NUS CS Joint faculty names\n",
    "    nus_joint_list = []\n",
    "    for row in results[2].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        nus_joint_list.append(fac_name)\n",
    "        \n",
    "    # List to store NUS CS Teaching faculty names\n",
    "    nus_teaching_list = []\n",
    "    for row in results[3].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        nus_teaching_list.append(fac_name)\n",
    "        \n",
    "    # List to store NUS CS Research faculty names\n",
    "    nus_research_list = []\n",
    "    for row in results[3].find_all(\"tr\")[1:]:\n",
    "        col = row.find_all(\"td\")\n",
    "        fac_name = col[0].getText().strip()\n",
    "        nus_research_list.append(fac_name)\n",
    "    \n",
    "    return nus_regular_list, nus_joint_list, nus_teaching_list, nus_research_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-norwegian",
   "metadata": {},
   "source": [
    "# 5. UCB Faculty Name List Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "approved-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_ucb_list():\n",
    "\n",
    "    # BS4 steps to get UCB CS faculty soup and details\n",
    "    page = requests.get('https://www2.eecs.berkeley.edu/Faculty/Lists/CS/faculty.html?_ga=2.57244906.1713537701.1616564430-341988066.1616564430')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all(\"h3\", {\"class\": \"media-heading\"})\n",
    "\n",
    "    # List to store UCB CS faculty names\n",
    "    ucb_faculty_list = []\n",
    "    for each in results:\n",
    "        detail = each.find('a')\n",
    "        fac_name = detail.getText()\n",
    "        ucb_faculty_list.append(fac_name)\n",
    "\n",
    "    # BS4 steps to get UCB CS teaching soup and details\n",
    "    page = requests.get('https://www2.eecs.berkeley.edu/Faculty/Lists/teaching.html?_ga=2.57244906.1713537701.1616564430-341988066.1616564430')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all(\"h3\", {\"class\": \"media-heading\"})    \n",
    "\n",
    "    # List to store UCB CS teaching names\n",
    "    ucb_teaching_list = []\n",
    "    for each in results:\n",
    "        detail = each.find('a')\n",
    "        fac_name = detail.getText()\n",
    "        ucb_teaching_list.append(fac_name)\n",
    "\n",
    "    return ucb_faculty_list, ucb_teaching_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faced-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_list = [[retrieve_mit_list()], [retrieve_stanford_list()], [retrieve_cmu_list()], [retrieve_nus_list()], [retrieve_ucb_list()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prospective-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_5_list.pkl', 'wb') as f:\n",
    "    pickle.dump(top_5_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "relative-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve pretty_soup_list with pickle\n",
    "with open('top_5_list.pkl', 'rb') as f:\n",
    "    top_5_list = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "suffering-affect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Hal Abelson',\n",
       "   'Regina Barzilay',\n",
       "   'Robert Berwick',\n",
       "   'Tamara Broderick',\n",
       "   'Rodney Brooks',\n",
       "   'Randall Davis',\n",
       "   'Fredo Durand',\n",
       "   'William Freeman',\n",
       "   'David Gifford',\n",
       "   'Polina Golland',\n",
       "   'W. Eric L. Grimson',\n",
       "   'John Guttag',\n",
       "   'Berthold Horn',\n",
       "   'Tommi Jaakkola',\n",
       "   'Stefanie Jegelka',\n",
       "   'Leslie Kaelbling',\n",
       "   'David Karger',\n",
       "   'Manolis Kellis',\n",
       "   'Tomás Lozano-Pérez',\n",
       "   'Wojciech Matusik',\n",
       "   'Rob Miller',\n",
       "   'Joel Moses',\n",
       "   'Daniela Rus',\n",
       "   'Devavrat Shah',\n",
       "   'Justin Solomon',\n",
       "   'David Sontag',\n",
       "   'Gerald Sussman',\n",
       "   'Vivienne Sze',\n",
       "   'Peter Szolovits',\n",
       "   'Russell Tedrake',\n",
       "   'Bruce Tidor',\n",
       "   'Antonio Torralba',\n",
       "   'Alan Willsky',\n",
       "   'Victor Zue'],\n",
       "  ['Fadel Adib',\n",
       "   'Mohammad Alizadeh',\n",
       "   'Saman Amarasinghe',\n",
       "   ' Arvind',\n",
       "   'Hari Balakrishnan',\n",
       "   'Adam Belay',\n",
       "   'Michael Carbin',\n",
       "   'Adam Chlipala',\n",
       "   'Henry Corrigan-Gibbs',\n",
       "   'Jack Dennis',\n",
       "   'Srini Devadas',\n",
       "   'Joel Emer',\n",
       "   'Manya Ghobadi',\n",
       "   'Daniel Jackson',\n",
       "   'M. Frans Kaashoek',\n",
       "   'David Karger',\n",
       "   'Dina Katabi',\n",
       "   'Tim Kraska ',\n",
       "   'Butler Lampson',\n",
       "   'Barbara Liskov',\n",
       "   'Samuel Madden',\n",
       "   'Rob Miller',\n",
       "   'Robert Morris',\n",
       "   'Martin Rinard',\n",
       "   'Daniel Sanchez Martin',\n",
       "   'Armando Solar-Lezama',\n",
       "   'Michael Stonebraker',\n",
       "   'Vivienne Sze',\n",
       "   'Stephen Ward',\n",
       "   'Nickolai Zeldovich'],\n",
       "  ['Constantinos Daskalakis',\n",
       "   'Erik Demaine',\n",
       "   'Shafi Goldwasser',\n",
       "   'Piotr Indyk',\n",
       "   'David Karger',\n",
       "   'Charles Leiserson',\n",
       "   'Nancy Lynch',\n",
       "   'Aleksander Madry',\n",
       "   'Thomas Magnanti',\n",
       "   'Albert Meyer',\n",
       "   'Silvio Micali',\n",
       "   'Ronald Rivest',\n",
       "   'Ronitt Rubinfeld',\n",
       "   'Nir Shavit',\n",
       "   'Justin Solomon',\n",
       "   'Vinod Vaikuntanathan',\n",
       "   'Jacob White',\n",
       "   'Virginia Williams',\n",
       "   'Ryan Williams'],\n",
       "  ['Zachary Abel',\n",
       "   'Jehangir Amjad',\n",
       "   'Ana Bell',\n",
       "   'Iddo Drori',\n",
       "   'Tony Eng',\n",
       "   'Max Goldman',\n",
       "   'Hsiu C. Han',\n",
       "   'Silvina Z. Hanono Wachman',\n",
       "   'Adam Hartz',\n",
       "   'Gim P. Hom',\n",
       "   'Mauricio Karchmer ',\n",
       "   'Kimberle Koile',\n",
       "   'Kenneth Kolodziej',\n",
       "   'Katrina LaCurts',\n",
       "   'Robert T-I Shin',\n",
       "   'Joseph D. Steinmeyer',\n",
       "   'Christopher Terman',\n",
       "   'James Ward'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-group",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
