{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appointed-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ordinary-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "asian-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import faculty details into df\n",
    "faculty_df = pd.read_excel('Faculty.xlsx')\n",
    "\n",
    "# Select relevant columns\n",
    "faculty_df = faculty_df[['Faculty', 'Position', 'Gender', 'Management', 'DBLP', 'Area']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-retailer",
   "metadata": {},
   "source": [
    "# Don't need to run this code for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list for storing modified DBLP link to access XML variant w/ their API\n",
    "xml_list = []\n",
    "\n",
    "# Iterate over faculty_df and replace .html w/ .xml\n",
    "for each in faculty_df['DBLP']:\n",
    "    replaced_each = each.replace(\".html\", \".xml\")\n",
    "    xml_list.append(replaced_each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare list to store extracted content\n",
    "content_list = []\n",
    "\n",
    "i = 0\n",
    "# Iterate using q_list to make a GET request to fetch raw HTML content\n",
    "for each in xml_list:\n",
    "    html_content = requests.get(each).text\n",
    "    content_list.append(html_content)\n",
    "    i+=1\n",
    "    if (i % 10 == 0):\n",
    "        print(i)\n",
    "    \n",
    "# Store content_list with pickle\n",
    "with open('content_list.pkl', 'wb') as f:\n",
    "    pickle.dump(content_list, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve content_list with pickle\n",
    "with open('content_list.pkl', 'rb') as f:\n",
    "    content_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare empty list for storing soups\n",
    "pretty_soup_list = []\n",
    "\n",
    "for each in content_list:\n",
    "    soup = BeautifulSoup(each, \"lxml\")\n",
    "    pretty_soup_list.append(soup.prettify())\n",
    "\n",
    "# Store pretty_soup_list with pickle\n",
    "with open('pretty_soup_list.pkl', 'wb') as f:\n",
    "    pickle.dump(pretty_soup_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-inquiry",
   "metadata": {},
   "source": [
    "# Run from here onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confused-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve pretty_soup_list with pickle\n",
    "with open('pretty_soup_list.pkl', 'rb') as f:\n",
    "    pretty_soup_list = pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "floppy-germany",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Declare empty all_article_list\n",
    "all_article_list = []\n",
    "faculty_dblp_name_list = []\n",
    "\n",
    "# Iterate over pretty_soup_list + extract names because given names in excel aren't same as DBLP lmao\n",
    "for each in pretty_soup_list:\n",
    "    converted_each = BeautifulSoup(each, \"lxml\") # need to convert lmao\n",
    "    individual_article_list = converted_each.find_all('article')\n",
    "    all_article_list.append(individual_article_list)\n",
    "    try:\n",
    "        faculty_dblp_name = converted_each.dblpperson['name']\n",
    "    except:\n",
    "        faculty_dblp_name = converted_each.title.text.strip().strip('dblp: ') # omg cancerous code sorry\n",
    "    finally:\n",
    "        faculty_dblp_name_list.append(faculty_dblp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seeing-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "all_article_list[0] <- Faculty, List Containing Articles\n",
    "all_article_list[0][0] <- Faculty, Individual Articles\n",
    "'''\n",
    "\n",
    "# Index for doing dict mapping later\n",
    "faculty_index = 0\n",
    "\n",
    "# declare empty lists for DF\n",
    "article_key_list = []\n",
    "article_mdate_list = []\n",
    "faculty_index_list = []\n",
    "title_list = []\n",
    "#pages_list = []\n",
    "year_list = []\n",
    "volume_list = []\n",
    "journal_list = []\n",
    "authors_list = []\n",
    "\n",
    "for each in all_article_list:\n",
    "    for article in each:\n",
    "        # Article Tag Extraction w/ Array Indexing\n",
    "        article_key = article[\"key\"]\n",
    "        article_mdate = article[\"mdate\"]\n",
    "        # Strip processing \n",
    "        stripped_title = article.title.text.strip()\n",
    "        #stripped_pages = article.pages.text.strip() <- apparently we have null pages somewhere?\n",
    "        stripped_year = article.year.text.strip()\n",
    "        stripped_volume = article.volume.text.strip()\n",
    "        stripped_journal = article.journal.text.strip() \n",
    "        stripped_authors = [each.text.strip() for each in article.find_all('author')] # list comprehension; bad space and time complexity  \n",
    "        # List appendage\n",
    "        article_key_list.append(article_key)\n",
    "        article_mdate_list.append(article_mdate)\n",
    "        faculty_index_list.append(faculty_index)\n",
    "        title_list.append(stripped_title)\n",
    "        #pages_list.append(stripped_pages)\n",
    "        year_list.append(stripped_year)\n",
    "        volume_list.append(stripped_volume)\n",
    "        journal_list.append(stripped_journal)\n",
    "        authors_list.append(stripped_authors)\n",
    "    faculty_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "protecting-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare DF for DBLP\n",
    "dblp_df = pd.DataFrame()\n",
    "\n",
    "# Create dict mapping for Faculty, len is used as f_index.\n",
    "faculty_dict_mapping = dict(zip(range(len(faculty_df['Faculty'])), faculty_df['Faculty'],))\n",
    "\n",
    "# Create another dict mapping for actual DBLP names used for faculty members, len is used f_index\n",
    "faculty_dblp_name_dict_mapping = dict(zip(range(len(faculty_df['Faculty'])), faculty_dblp_name_list,))\n",
    "\n",
    "# Fill up dblp_DF\n",
    "dblp_df['f_index'] = faculty_index_list\n",
    "dblp_df['Faculty'] = dblp_df['f_index'].map(faculty_dict_mapping)\n",
    "dblp_df['DBLP Name'] = dblp_df['f_index'].map(faculty_dblp_name_dict_mapping)\n",
    "dblp_df['key'] = article_key_list\n",
    "dblp_df['mdate'] = article_mdate_list\n",
    "dblp_df['Title'] = title_list\n",
    "dblp_df['Year'] = year_list\n",
    "#dblp_df['Volume'] = volume_list\n",
    "dblp_df['Journal'] = journal_list\n",
    "dblp_df['Other Authors'] = authors_list\n",
    "dblp_df['Full Authors List'] = authors_list\n",
    "\n",
    "# Code for inserting contribution into DF\n",
    "contribution_index_list = []\n",
    "for i, row in dblp_df.iterrows():\n",
    "    if (row['DBLP Name'] in row['Full Authors List']): # check if DBLP name exists in Full Authors List\n",
    "        ci = row['Full Authors List'].index(row['DBLP Name'])+1 # if so, retrieve index, +1 (to acccount for 0), then append to contribution_index_list\n",
    "    elif (row['Faculty'] in row['Full Authors List']): # check if Faculty name exists in Full Authors List\n",
    "        ci = row['Full Authors List'].index(row['Faculty'])+1\n",
    "    else:\n",
    "        ci = '-'\n",
    "    contribution_index_list.append(ci)\n",
    "dblp_df['Author Contribution Index'] = contribution_index_list # assigns a value based on how much contribution the author has made for a publication. 1 = Highest (Main)\n",
    "\n",
    "# Use DBLP Name Column to prune duplicate author info from 'Other Authors'colmumn row-by-row (because DBLP name is not same as Faculty name lmao)\n",
    "for i, row in dblp_df.iterrows():\n",
    "    if (row['DBLP Name'] in row['Other Authors']): # check if DBLP faculty name exists in Other Authors.\n",
    "        row['Other Authors'].remove(row['DBLP Name']) # if so, remove from Other Authors\n",
    "    elif (row['Faculty'] in row['Other Authors']): # then check if faculty name exists in Other Authors\n",
    "        row['Other Authors'].remove(row['Faculty']) # if so, remove from Other Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lesser-manitoba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_index</th>\n",
       "      <th>Faculty</th>\n",
       "      <th>DBLP Name</th>\n",
       "      <th>key</th>\n",
       "      <th>mdate</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Other Authors</th>\n",
       "      <th>Full Authors List</th>\n",
       "      <th>Author Contribution Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A S Madhukumar</td>\n",
       "      <td>A. S. Madhukumar</td>\n",
       "      <td>journals/cssp/MathewSVM20</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>An Adaptive Energy Detection Scheme with Real-...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Circuits Syst. Signal Process.</td>\n",
       "      <td>[Libin K. Mathew, Shanker Shreejith, A. Prasad...</td>\n",
       "      <td>[Libin K. Mathew, Shanker Shreejith, A. Prasad...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_index         Faculty         DBLP Name                        key  \\\n",
       "0        0  A S Madhukumar  A. S. Madhukumar  journals/cssp/MathewSVM20   \n",
       "\n",
       "        mdate                                              Title  Year  \\\n",
       "0  2020-10-20  An Adaptive Energy Detection Scheme with Real-...  2020   \n",
       "\n",
       "                          Journal  \\\n",
       "0  Circuits Syst. Signal Process.   \n",
       "\n",
       "                                       Other Authors  \\\n",
       "0  [Libin K. Mathew, Shanker Shreejith, A. Prasad...   \n",
       "\n",
       "                                   Full Authors List Author Contribution Index  \n",
       "0  [Libin K. Mathew, Shanker Shreejith, A. Prasad...                         4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dblp_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "challenging-evolution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dblp_df.loc[dblp_df['Author Contribution Index'] == '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "passive-privacy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dblp_df.to_csv(r'dblp_df.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
