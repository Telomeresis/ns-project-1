{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appointed-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pickle\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-category",
   "metadata": {},
   "source": [
    "# Step 1: Loading Provided Faculty Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "asian-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faculty():\n",
    "    # Import faculty details into df\n",
    "    faculty_df = pd.read_excel('Faculty.xlsx')\n",
    "    # Select relevant columns\n",
    "    faculty_df = faculty_df[['Faculty', 'Position', 'Gender', 'Management', 'DBLP', 'Area']]\n",
    "    return faculty_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-retailer",
   "metadata": {},
   "source": [
    "# Step 2: Scraping DBLP HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reverse-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_dblp(faculty_df):\n",
    "    # Create empty list for storing modified DBLP link to access XML variant w/ their API\n",
    "    xml_list = []\n",
    "    # Iterate over faculty_df and replace .html w/ .xml - updated to append .xml for missing .html cases\n",
    "    for each in faculty_df['DBLP']:\n",
    "        if '.html' in each:\n",
    "            replaced_each = each.replace(\".html\", \".xml\")\n",
    "        xml_list.append(replaced_each)\n",
    "\n",
    "    # Declare list to store extracted content\n",
    "    content_list = []\n",
    "\n",
    "    i = 0\n",
    "    # Iterate using q_list to make a GET request to fetch raw HTML content\n",
    "    for each in xml_list:\n",
    "        html_content = requests.get(each).text\n",
    "        content_list.append(html_content)\n",
    "        i+=1\n",
    "        if (i % 10 == 0):\n",
    "            print(i)\n",
    "            \n",
    "    # Store content_list with pickle\n",
    "    with open('content_list.pkl', 'wb') as f:\n",
    "        pickle.dump(content_list, f)\n",
    "    \n",
    "    return content_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-mozambique",
   "metadata": {},
   "source": [
    "# Step 3: Parsing DBLP HTML w/ BS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dblp(content_list):\n",
    "\n",
    "    # Declare empty list for storing soups\n",
    "    pretty_soup_list = []\n",
    "\n",
    "    for each in content_list:\n",
    "        soup = BeautifulSoup(each, \"lxml\")\n",
    "        pretty_soup_list.append(soup.prettify())\n",
    "\n",
    "    # Store pretty_soup_list with pickle\n",
    "    with open('pretty_soup_list.pkl', 'wb') as f:\n",
    "        pickle.dump(pretty_soup_list, f)\n",
    "    \n",
    "    return pretty_soup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_articles_conf(pretty_soup_list):\n",
    "    # Declare empty all_article_list\n",
    "    all_article_list = []\n",
    "    faculty_dblp_name_list = []\n",
    "\n",
    "    # Iterate over pretty_soup_list + extract names because given names in excel aren't same as DBLP lmao\n",
    "    for each in pretty_soup_list:\n",
    "        converted_each = BeautifulSoup(each, \"lxml\") # need to convert lmao\n",
    "        individual_article_list = converted_each.find_all('article')\n",
    "        individual_article_list += converted_each.find_all('inproceedings')\n",
    "        all_article_list.append(individual_article_list)\n",
    "        try:\n",
    "            faculty_dblp_name = converted_each.dblpperson['name']\n",
    "        except:\n",
    "            faculty_dblp_name = converted_each.title.text.strip().strip('dblp: ') # omg cancerous code sorry\n",
    "        finally:\n",
    "            #print(faculty_dblp_name)\n",
    "            faculty_dblp_name_list.append(faculty_dblp_name)\n",
    "            \n",
    "    return all_article_list, faculty_dblp_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-smooth",
   "metadata": {},
   "source": [
    "# Step 4: Dataframe Creation & Population w/ Parsed DBLP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare DF for DBLP\n",
    "COLUMN_NAMES=[\n",
    "    'f_index',\n",
    "    'Faculty',\n",
    "    'key',\n",
    "    'Year',\n",
    "    'Full Authors List'\n",
    "]\n",
    "dblp_df = pd.DataFrame(columns=COLUMN_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "all_article_list[0] <- Faculty, List Containing Articles\n",
    "all_article_list[0][0] <- Faculty, Individual Articles\n",
    "'''\n",
    "\n",
    "def df_population(dblp_df):\n",
    "    # Index for doing dict mapping later\n",
    "    faculty_index = 0\n",
    "\n",
    "    # declare empty lists for DF\n",
    "    article_key_list = []\n",
    "    article_mdate_list = []\n",
    "    faculty_index_list = []\n",
    "    title_list = []\n",
    "    year_list = []\n",
    "    authors_list = []\n",
    "\n",
    "    for each in all_article_list:\n",
    "        for article in each:\n",
    "            # Article Tag Extraction w/ Array Indexing\n",
    "            article_key = article[\"key\"]\n",
    "            article_mdate = article[\"mdate\"]\n",
    "            # Strip processing \n",
    "            stripped_year = article.year.text.strip()\n",
    "            stripped_authors = [each.text.strip() for each in article.find_all('author')] # list comprehension; bad space and time complexity  \n",
    "            # Append to df\n",
    "            append_dict = {'f_index': faculty_index, 'Faculty': '', 'key': article_key, 'Year': stripped_year, 'Full Authors List': stripped_authors}\n",
    "            dblp_df = dblp_df.append(append_dict, ignore_index=True)\n",
    "\n",
    "        faculty_index+=1\n",
    "\n",
    "    # Create dict mapping for Faculty, len is used as f_index.\n",
    "    faculty_dict_mapping = dict(zip(range(len(faculty_df['Faculty'])), faculty_df['Faculty'],))\n",
    "    dblp_df['Faculty'] = dblp_df['f_index'].map(faculty_dict_mapping)\n",
    "\n",
    "    # Store dblp_df with pickle\n",
    "    with open('dblp_12k_df.pkl', 'wb') as f:\n",
    "        pickle.dump(dblp_df, f)\n",
    "    return dblp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-loading",
   "metadata": {},
   "source": [
    "# Run from here onwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-traffic",
   "metadata": {},
   "source": [
    "# Step 5: Dataframe Post-Processing (NLP & Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "french-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve dblp_df with pickle\n",
    "with open('dblp_12k_df.pkl', 'rb') as f:\n",
    "    dblp_df = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "regional-content",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A. S. Madhukumar'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_name_form_in_list(fac_name, authors_list):\n",
    "    mod_fac_name = fac_name.replace(\"-\", \" \")\n",
    "    mod_fac_name_list = mod_fac_name.split(\" \")\n",
    "    #print(mod_fac_name_list)\n",
    "    best_i = 0\n",
    "    best_count = 0\n",
    "    \n",
    "    for i in range(len(authors_list)):\n",
    "        #check matchability\n",
    "        author = authors_list[i]\n",
    "        count = 0\n",
    "        for w in mod_fac_name_list:\n",
    "            if w in author:\n",
    "                count += 1\n",
    "        if count > best_count:\n",
    "            best_count = count \n",
    "            best_i = i\n",
    "    return authors_list[best_i]\n",
    "\n",
    "find_name_form_in_list(dblp_df.iloc[0, 1], dblp_df.iloc[0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "declared-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_df[\"published_name\"] = dblp_df.apply(lambda row: find_name_form_in_list(row[\"Faculty\"], row[\"Full Authors List\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "earned-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_calculation(dblp_df):\n",
    "    # Code for inserting contribution into DF\n",
    "    contribution_index_list = []\n",
    "    for i, row in dblp_df.iterrows():\n",
    "        if (row['published_name'] in row['Full Authors List']): # check if DBLP name exists in Full Authors List\n",
    "            ci = row['Full Authors List'].index(row['published_name'])+1 # if so, retrieve index, +1 (to acccount for 0), then append to contribution_index_list\n",
    "        else:\n",
    "            ci = '-'\n",
    "        contribution_index_list.append(ci)\n",
    "    dblp_df['Author Contribution Index'] = contribution_index_list # assigns a value based on how much contribution the author has made for a publication. 1 = Highest (Main)\n",
    "    return dblp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DBLP Name Column to prune duplicate author info from 'Other Authors'colmumn row-by-row (because DBLP name is not same as Faculty name lmao)\n",
    "authors_list = dblp_df['Full Authors List'].tolist()\n",
    "#dblp_df['Other Authors'] = authors_list.copy()\n",
    "#dblp_df['Other Authors'] = others_list # assigns a value based on how much contribution the author has made for a publication. 1 = Highest (Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "industrial-laser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def prune_name_from_other_authors_list(fac_name, authors_list):\n",
    "    mod_fac_name = fac_name.replace(\"-\", \" \")\n",
    "    mod_fac_name_list = mod_fac_name.split(\" \")\n",
    "    #print(mod_fac_name_list)\n",
    "    best_i = 0\n",
    "    best_count = 0\n",
    "    \n",
    "    for i in range(len(authors_list)):\n",
    "        #check matchability\n",
    "        author = authors_list[i]\n",
    "        count = 0\n",
    "        for w in mod_fac_name_list:\n",
    "            if w in author:\n",
    "                count += 1\n",
    "        if count > best_count:\n",
    "            best_count = count \n",
    "            best_i = i\n",
    "    authors_list.remove(authors_list[best_i])\n",
    "    dblp_df['Other Authors'] = dblp_df['Full Authors List'].copy() # assigns a value based on how much contribution the author has made for a publication. 1 = Highest (Main)\n",
    "    dblp_df.apply(lambda row: prune_name_from_other_authors_list(row[\"Faculty\"], row[\"Other Authors\"]), axis = 1)\n",
    "    return dblp_df\n",
    "\n",
    "# Use DBLP Name Column to prune duplicate author info from 'Other Authors'colmumn row-by-row (because DBLP name is not same as Faculty name lmao)\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-cardiff",
   "metadata": {},
   "source": [
    "# Step 6: Dataframe to CSV Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "respiratory-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_df.to_csv(r'dblp_df_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-opposition",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dblp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-collar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
